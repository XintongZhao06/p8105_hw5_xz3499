---
title: "p8105_mtp_xz3499"
author: "Xintong Zhao"
date: "`r Sys.Date()`"
output: github_document
---

```{r, echo=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,           
  warning = FALSE,       
  message = FALSE           
)
```

```{r}
library(tidyverse)
library(ggplot2)
library(broom)
```

## Problem 1
```{r}
check_duplicate_birthdays <- function(n) {
  birthdays <- sample(1:365, size = n, replace = TRUE)
  repeated_bday = length(unique(birthdays)) < n
  repeated_bday
}

set.seed(123)

birthday_sim_results <- expand_grid(
  group_size = 2:50,
  iteration = 1:10000
) %>%
  mutate(
    has_duplicate = map_lgl(group_size, check_duplicate_birthdays)
  ) %>%
  group_by(group_size) %>%
  summarize(
    prob_duplicate = mean(has_duplicate)
  )

birthday_plot <- birthday_sim_results %>%
  ggplot(aes(x = group_size, y = prob_duplicate)) +
  geom_line(color = "steelblue", size = 1) +
  geom_point(color = "steelblue", size = 1) +
  labs(
    title = "Probability of Shared Birthday by Group Size",
    x = "Number of People in Group",
    y = "Probability of at Least One Shared Birthday",
    caption = "Based on 10,000 simulations per group size"
  ) +
  theme_minimal() +
  scale_y_continuous(labels = scales::percent_format()) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    panel.grid.minor = element_blank()
  )

birthday_plot
```

Comment:

The probability curve grows rapidly in an S shape. When the number of people in a group is 23, the probability exceeds 50%. When the number of people in a group is around 40, the probability exceeds 90%. This goes against our intuition that 183 people are needed to have a 50% chance. This is because as the number of people increases, the possible number of birthday pairings grows exponentially, causing the probability of repetition to increase rapidly.

## Problem 2

```{r}
n <- 30
sigma <- 5
alpha <- 0.05
mu_values <- c(0, 1, 2, 3, 4, 5, 6)
n_sims <- 5000

# Function to simulate data and perform t-test
simulate_ttest <- function(mu, n, sigma) {
  data <- rnorm(n, mean = mu, sd = sigma)
  test_result <- t.test(data, mu = 0)
  tidy_result <- broom::tidy(test_result)
  
  return(tibble(
    mu_hat = tidy_result$estimate,
    p_value = tidy_result$p.value
  ))
}

set.seed(123)

power_sim_results <- expand_grid(
  true_mu = mu_values,
  iter = 1:n_sims
) %>%
  mutate(
    test_results = map(true_mu, ~ simulate_ttest(.x, n, sigma))
  ) %>%
  unnest(test_results) %>%
  mutate(
    rejected = p_value < alpha
  )
```

### The power of the test

```{r}
power_curve <- power_sim_results %>%
  group_by(true_mu) %>%
  summarize(
    power = mean(rejected),
    se_power = sqrt(power * (1 - power) / n())
  ) %>%
  ggplot(aes(x = true_mu, y = power)) +
  geom_line(color = "steelblue", size = 1.2) +
  geom_point(color = "steelblue", size = 2) +
  geom_errorbar(aes(ymin = power - 1.96 * se_power, 
                    ymax = power + 1.96 * se_power), 
                width = 0.1, color = "steelblue") +
  labs(
    title = "Statistical Power vs True Mean",
    subtitle = paste("n =", n, ", σ =", sigma, ", α =", alpha),
    x = "True Mean μ",
    y = "Power (Probability of Rejecting H₀)"
  ) +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent_format()) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5)
  )

print(power_curve)
```

Description:

The statistical Power increases rapidly with the increase of the True Mean (μ). The efficacy exceeds 50% approximately when μ = 2, exceeds 80% when μ = 3, and almost reaches 100% when μ ≥ 4. This is because the larger the effect size, the easier it is for the sample mean to deviate from the expected value (μ₀) under the null hypothesis, and thus it is more likely to be detected by statistical tests. 

### Mean estimation comparison

```{r}
mean_estimates <- power_sim_results %>%
  group_by(true_mu) %>%
  summarize(
    overall_mean = mean(mu_hat),
    rejected_mean = mean(mu_hat[rejected])
  )

estimate_plot <- ggplot(mean_estimates, aes(x = true_mu)) +
  geom_line(aes(y = overall_mean, color = "All Samples"), size = 1.2) +
  geom_point(aes(y = overall_mean, color = "All Samples"), size = 2) +
  geom_line(aes(y = rejected_mean, color = "Rejected Samples"), size = 1.2) +
  geom_point(aes(y = rejected_mean, color = "Rejected Samples"), size = 2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", 
              color = "gray", alpha = 0.7) +
  labs(
    title = "Mean Estimates vs True Mean",
    subtitle = paste("n =", n, ", σ =", sigma),
    x = "True Mean μ",
    y = "Estimated Mean μ̂",
    color = "Sample Type"
  ) +
  scale_color_manual(values = c("All Samples" = "lightblue", 
                               "Rejected Samples" = "lightpink")) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5),
    legend.position = "bottom"
  )

print(estimate_plot)
```

Description:

When μ is small (0 to 2), the number of rejected samples is higher than that of all samples and above the dotted line of the true mean, which means that the samples that reject the null hypothesis tend to have a higher estimated mean. When μ is large (≥3), the two lines almost coincide, and the estimated value is close to the true μ. This is because when the effect size is small, the null hypothesis will only be rejected when the sample mean is unexpectedly high. Therefore, the average estimate of the rejected sample will be systematically high (selective bias). When the effect size is large enough, almost all samples can reject the null hypothesis. At this point, the rejected samples are almost consistent with the population sample, and the bias disappears.


